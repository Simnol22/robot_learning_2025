{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dJZuqlWdvL2H",
        "outputId": "05f50d80-0ff1-4864-ea1d-6d7a9d498bdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'robot_learning_2025'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 122 (delta 41), reused 110 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (122/122), 17.97 MiB | 17.69 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "/content/robot_learning_2025/hw2/robot_learning_2025/hw2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: pandas==2.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: tensorflow_datasets==4.9.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.9.2)\n",
            "Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.8.0)\n",
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.0.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.2.0)\n",
            "Requirement already satisfied: Pillow==9.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (9.4.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.19.5)\n",
            "Requirement already satisfied: hydra-core==1.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (1.1.1)\n",
            "Requirement already satisfied: hydra-optuna-sweeper in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.2.0)\n",
            "Requirement already satisfied: hydra-submitit-launcher in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (4.48.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 5)) (0.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1->-r requirements.txt (line 7)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1->-r requirements.txt (line 7)) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (0.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (0.1.9)\n",
            "Requirement already satisfied: etils>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (1.11.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (1.16.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (0.10.2)\n",
            "Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.1.1->-r requirements.txt (line 18)) (2.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.1.1->-r requirements.txt (line 18)) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.1.*->hydra-core==1.1.1->-r requirements.txt (line 18)) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.11/dist-packages (from dm-reverb->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 14)) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 14)) (0.28.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (4.3.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 17)) (1.3.4)\n",
            "Requirement already satisfied: optuna<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from hydra-optuna-sweeper->-r requirements.txt (line 19)) (2.10.1)\n",
            "Requirement already satisfied: submitit>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from hydra-submitit-launcher->-r requirements.txt (line 20)) (1.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 21)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 21)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 21)) (0.5.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0->-r requirements.txt (line 9)) (0.45.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (3.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 17)) (4.0.12)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (1.14.1)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (4.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (0.11.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (6.9.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (2.0.37)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 17)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->-r requirements.txt (line 5)) (2025.1.31)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit>=1.3.3->hydra-submitit-launcher->-r requirements.txt (line 20)) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow_datasets==4.9.2->-r requirements.txt (line 10)) (1.66.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 17)) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (2.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (1.3.9)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (3.14.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (0.5.2)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (2.5.11)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (5.4.0)\n",
            "Requirement already satisfied: pyperclip>=1.8 in /usr/local/lib/python3.11/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (1.9.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.10 in /usr/local/lib/python3.11/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.10.0->hydra-optuna-sweeper->-r requirements.txt (line 19)) (6.1.1)\n",
            "Collecting mediapy\n",
            "  Downloading mediapy-1.2.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapy) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mediapy) (9.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.17.0)\n",
            "Downloading mediapy-1.2.2-py3-none-any.whl (26 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, mediapy\n",
            "Successfully installed jedi-0.19.2 mediapy-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/milarobotlearningcourse/robot_learning_2025.git\n",
        "%cd robot_learning_2025/hw2\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install mediapy\n",
        "# Install repo\n",
        "import cv2\n",
        "import tensorflow_datasets as tfds\n",
        "import tqdm\n",
        "import rlds, numpy as np\n",
        "import mediapy as media\n",
        "from PIL import Image\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N81yWJ3zvL2J"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython import display\n",
        "def as_gif(images, path='temp.gif'):\n",
        "  # Render the images as the gif:\n",
        "  images = [Image.fromarray(image) for image in images]\n",
        "  images[0].save(path, save_all=True, append_images=images[1:], duration=1000, loop=0)\n",
        "  gif_bytes = open(path,'rb').read()\n",
        "  return gif_bytes\n",
        "\n",
        "# create RLDS dataset builder\n",
        "builder = tfds.builder_from_directory(builder_dir='gs://gresearch/robotics/bridge/0.1.0/')\n",
        "dataset = builder.as_dataset(split='train[:1]')\n",
        "\n",
        "# sample episode + resize to 256x256 (default third-person cam resolution)\n",
        "episode = next(iter(dataset))\n",
        "print(episode)\n",
        "\n",
        "steps = list(episode['steps'])\n",
        "images = np.array([cv2.resize(np.array(step['observation']['image']), (256, 256)) for step in steps])\n",
        "\n",
        "# extract goal image & language instruction\n",
        "goal_image = images[-1]\n",
        "language_instruction = steps[0]['observation']['natural_language_instruction'].numpy().decode()\n",
        "\n",
        "# visualize episode\n",
        "print(f'Instruction: {language_instruction}')\n",
        "display.Image(as_gif(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--hMjYt0vL2K"
      },
      "outputs": [],
      "source": [
        "## Looking at the actions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "actions = np.array([np.array(step['action']['world_vector']) for step in steps])\n",
        "\n",
        "plt.plot(actions[:, 0], label='x')\n",
        "plt.plot(actions[:, 1], label='y')\n",
        "plt.plot(actions[:, 2], label='z')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-A2s0J4vL2K"
      },
      "outputs": [],
      "source": [
        "## Install SimpleEnv for evaluation in the simulation\n",
        "# @title Install vulkan for rendering\n",
        "!apt-get install -yqq --no-install-recommends libvulkan-dev vulkan-tools\n",
        "# below fixes some bugs introduced by some recent Colab changes\n",
        "!mkdir -p /usr/share/vulkan/icd.d\n",
        "!wget -q -P /usr/share/vulkan/icd.d https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/nvidia_icd.json\n",
        "!wget -q -O /usr/share/glvnd/egl_vendor.d/10_nvidia.json https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/10_nvidia.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjmUq6LPvL2K"
      },
      "outputs": [],
      "source": [
        "# @title Make sure vulkan is installed correctly\n",
        "!vulkaninfo | head -n 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9BbTVPPvL2K"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/milarobotlearningcourse/SimplerEnv.git --recurse-submodules\n",
        "!pip install -e ./SimplerEnv/ManiSkill2_real2sim/\n",
        "!pip install -e ./SimplerEnv\n",
        "!mkdir ./SimplerEnv/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji2-7JoVvL2L"
      },
      "outputs": [],
      "source": [
        "import simpler_env\n",
        "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
        "import mediapy\n",
        "import sapien.core as sapien\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "task_name = \"widowx_carrot_on_plate\"  # @param [\"google_robot_pick_coke_can\", \"google_robot_move_near\", \"google_robot_open_drawer\", \"google_robot_close_drawer\", \"widowx_spoon_on_towel\", \"widowx_carrot_on_plate\", \"widowx_stack_cube\", \"widowx_put_eggplant_in_basket\"]\n",
        "\n",
        "if 'env' in locals():\n",
        "  print(\"Closing existing env\")\n",
        "  env.close()\n",
        "  del env\n",
        "env = simpler_env.make(task_name)\n",
        "# Colab GPU does not support denoiser\n",
        "sapien.render_config.rt_use_denoiser = False\n",
        "obs, reset_info = env.reset()\n",
        "instruction = env.get_language_instruction()\n",
        "print(\"Reset info\", reset_info)\n",
        "print(\"Instruction\", instruction)\n",
        "\n",
        "frames = []\n",
        "done, truncated = False, False\n",
        "while not (done or truncated):\n",
        "   # action[:3]: delta xyz; action[3:6]: delta rotation in axis-angle representation;\n",
        "   # action[6:7]: gripper (the meaning of open / close depends on robot URDF)\n",
        "   image = get_image_from_maniskill2_obs_dict(env, obs)\n",
        "   action = env.action_space.sample() # replace this with your policy inference\n",
        "   obs, reward, done, truncated, info = env.step(action)\n",
        "   frames.append(image)\n",
        "\n",
        "episode_stats = info.get('episode_stats', {})\n",
        "print(\"Episode stats\", episode_stats)\n",
        "# mediapy.show_video(frames, fps=10)\n",
        "import moviepy.editor as mpy\n",
        "clip = mpy.ImageSequenceClip(list(frames), fps=20)\n",
        "display.Image(as_gif(frames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGLlyUhgvL2L"
      },
      "outputs": [],
      "source": [
        "from hydra import compose, initialize\n",
        "initialize(config_path=\"./conf\", job_name=\"test_app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gENtRFkGvL2L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import cv2\n",
        "\n",
        "\n",
        "# data loading\n",
        "def get_batch_grp(split, dataset, batch_size):\n",
        "    # generate a small batch of inputs x and targets y\n",
        "    data = dataset['train'] if split == 'train' else dataset['test']\n",
        "    ix = np.random.randint(int(len(data[\"img\"])), size=(batch_size,))\n",
        "    x = torch.tensor(data[\"img\"][ix], dtype=torch.float)\n",
        "    x_goal = torch.tensor(data[\"goal\"][ix], dtype=torch.long)\n",
        "    x_goal_img = torch.tensor(data[\"goal_img\"][ix], dtype=torch.float)\n",
        "    y = torch.tensor(data[\"action\"][ix], dtype=torch.float)\n",
        "    return x, x_goal, x_goal_img, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(model._cfg.eval_iters)\n",
        "        for k in range(model._cfg.eval_iters):\n",
        "            X, x_goal, x_goal_img, Y = get_batch_grp(split, model._dataset, model._cfg.batch_size)\n",
        "            logits, loss = model(X, x_goal, x_goal_img, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "def get_patches_fast(images):\n",
        "    from einops import rearrange\n",
        "    batch_size, channels, height, width = images.shape\n",
        "    patch_size = height // 8 ## n_patches = 8\n",
        "\n",
        "    patches = rearrange(images, 'b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size)\n",
        "    return patches\n",
        "\n",
        "def calc_positional_embeddings(sequence_length, d):\n",
        "    result = torch.ones(sequence_length, d)\n",
        "    for i in range(sequence_length):\n",
        "        for j in range(d):\n",
        "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
        "    return result\n",
        "\n",
        "## This is an encoder head (full attention)\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, n_embd, dropout):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        # self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B,T,C = x.shape\n",
        "        TODO\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        ### Block masked attention\n",
        "        wei = wei.masked_fill(mask == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size, n_embd, dropout):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size, n_embd=n_embd, dropout=dropout) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, dropout):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x,)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head, dropout):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size, n_embd=n_embd, dropout=dropout)\n",
        "        self.ffwd = FeedFoward(n_embd, dropout)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = x + self.sa(self.ln1(x), mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GRP(nn.Module):\n",
        "  def __init__(self, dataset, cfg, mlp_ratio=4):\n",
        "    super(GRP, self).__init__()\n",
        "    self._dataset = dataset\n",
        "    self._cfg = cfg\n",
        "    TODO\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "      if isinstance(module, nn.Linear):\n",
        "          torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "          if module.bias is not None:\n",
        "              torch.nn.init.zeros_(module.bias)\n",
        "      elif isinstance(module, nn.Embedding):\n",
        "          torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "  def forward(self, images, goals_txt, goal_imgs, targets=None):\n",
        "    # Dividing images into patches\n",
        "    n, c, h, w = images.shape\n",
        "    B, T = goals_txt.shape\n",
        "    TODO\n",
        "\n",
        "import hydra, json\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "from hydra import compose, initialize\n",
        "\n",
        "# @hydra.main(config_path=\"conf\", config_name=\"grp-mini\")\n",
        "# @hydra.main(config_path=\"./conf\", config_name=\"bridge-64-light\")\n",
        "def my_main():\n",
        "    cfg = compose(config_path=\"./conf\", config_name=\"bridge-64-light\", overrides=[\"+env=absolute_path\"])\n",
        "\n",
        "    torch.manual_seed(cfg.r_seed)\n",
        "    print (\"cfg:\", OmegaConf.to_yaml(cfg))\n",
        "    torch.manual_seed(cfg.r_seed)\n",
        "    log_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir\n",
        "    print (\"cfg:\", OmegaConf.to_yaml(cfg))\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "    cfg.device = device\n",
        "    from datasets import load_dataset, load_from_disk\n",
        "\n",
        "    dataset = load_dataset(cfg.dataset.to_name, split='train')\n",
        "    print('Features:', dataset.features)\n",
        "\n",
        "    dataset_tmp = {\n",
        "        \"img\": np.array(dataset[\"img\"]),\n",
        "        \"action\": np.concatenate((np.array(dataset[\"action\"])\n",
        "                                ,np.array(dataset[\"rotation_delta\"])\n",
        "                                ,np.array(dataset[\"open_gripper\"])\n",
        "                                ), axis=1),\n",
        "        \"goal_img\": np.array(dataset[\"goal_img\"]),\n",
        "        \"goal\": dataset[\"goal\"]\n",
        "    }\n",
        "    shortest_text_len = min([len(txt) for txt in dataset[\"goal\"]])\n",
        "    cfg.block_size = shortest_text_len\n",
        "\n",
        "    # here are all the unique characters that occur in this text\n",
        "    chars = sorted(list(set([item for row in dataset_tmp[\"goal\"] for item in row]))) ## Flatten to a long string\n",
        "    cfg.vocab_size = len(chars)\n",
        "    # create a mapping from characters to integers\n",
        "    stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "    itos = { i:ch for i,ch in enumerate(chars) }\n",
        "    encode_txt = lambda s: [stoi[c] for c in s] # text encoder to tokens:\n",
        "    decode_txy = lambda l: ''.join([itos[i] for i in l]) # token decoder to text:\n",
        "    print(\"vocab_size:\", cfg.vocab_size)\n",
        "    print(\"example text encode:\", encode_txt(dataset_tmp[\"goal\"][0]))\n",
        "\n",
        "    TODO\n",
        "\n",
        "    ## Get the actions and encode them to map to [-1, 1]\n",
        "    encode_state = lambda af:   ((af/(255.0)*2.0)-1.0).astype(np.float32) # encoder: take a float, output an integer\n",
        "    resize_state = lambda sf:   cv2.resize(np.array(sf, dtype=np.float32), (cfg.image_shape[0], cfg.image_shape[1]))  # resize state\n",
        "\n",
        "    dataset_tmp = {\n",
        "        \"img\": torch.tensor(encode_state(dataset_tmp[\"img\"])).to(device),\n",
        "        \"action\": torch.tensor(encode_action(dataset_tmp[\"action\"]), dtype=torch.float).to(device),\n",
        "        \"goal_img\": torch.tensor(encode_state(dataset_tmp[\"goal_img\"])).to(device),\n",
        "        \"goal\": torch.tensor([encode_txt(goal[:cfg.block_size]) for goal in dataset_tmp[\"goal\"]]).to(device)\n",
        "    }\n",
        "\n",
        "    print(\"Dataset shape:\", len(dataset_tmp[\"img\"]))\n",
        "    dataset_tmp = {\"train\": dataset_tmp, \"test\": dataset_tmp}\n",
        "    if not cfg.testing:\n",
        "        import wandb\n",
        "        # start a new wandb run to track this script\n",
        "        wandb.init(\n",
        "            # set the wandb project where this run will be logged\n",
        "            project=cfg.experiment.project,\n",
        "\n",
        "            # track hyperparameters and run metadata\n",
        "            config= OmegaConf.to_container(cfg)\n",
        "        )\n",
        "        wandb.run.log_code(\".\")\n",
        "    model = GRP(dataset_tmp, cfg)\n",
        "    m = model.to(device)\n",
        "    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "    # create a PyTorch optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate)\n",
        "    import torch.optim.lr_scheduler as lr_scheduler\n",
        "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=cfg.max_iters)\n",
        "\n",
        "    if cfg.simEval:\n",
        "        import simpler_env\n",
        "        from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
        "        task_name = \"widowx_carrot_on_plate\"  # @param [\"google_robot_pick_coke_can\", \"google_robot_move_near\", \"google_robot_open_drawer\", \"google_robot_close_drawer\", \"widowx_spoon_on_towel\", \"widowx_carrot_on_plate\", \"widowx_stack_cube\", \"widowx_put_eggplant_in_basket\"]\n",
        "        if 'env' in locals():\n",
        "            print(\"Closing existing env\")\n",
        "            env.close()\n",
        "            del env\n",
        "        env = simpler_env.make(task_name)\n",
        "        env_unwrapped = env.env.env.env ## Updated gymnasium wrapper adds lots of wrappers.\n",
        "\n",
        "    for iter in range(cfg.max_iters):\n",
        "\n",
        "        if iter % cfg.eval_interval == 0 or iter == cfg.max_iters - 1:\n",
        "            losses = estimate_loss(model)\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "            if not cfg.testing:\n",
        "                wandb.log({\"train loss\": losses['train'], \"val loss\": losses['val']})\n",
        "\n",
        "            if cfg.simEval and (iter % cfg.eval_vid_iters == 0): ## Do this eval infrequently because it takes a fiar bit of compute\n",
        "                rewards = []\n",
        "                for j in range(cfg.sim.eval_episodes): ## Better to eval over a few different goal configurations\n",
        "                    obs, reset_info = env.reset()\n",
        "                    instruction = env_unwrapped.get_language_instruction()\n",
        "                    print(\"Reset info\", reset_info)\n",
        "                    print(\"Instruction\", instruction)\n",
        "                    frames = []\n",
        "                    done, truncated, timeLimit, t = False, False, 100, 0\n",
        "                    while not (done or truncated or (t > timeLimit)):\n",
        "                        # action[:3]: delta xyz; action[3:6]: delta rotation in axis-angle representation;\n",
        "                        # action[6:7]: gripper (the meaning of open / close depends on robot URDF)\n",
        "                        image = get_image_from_maniskill2_obs_dict(env_unwrapped, obs)\n",
        "                        image = image[:,:,:3] ## Remove last dimension of image color\n",
        "                        action, loss = model.forward(torch.tensor(np.array([encode_state(resize_state(image))])).to(device)\n",
        "                                            ,torch.tensor(np.array([encode_txt(instruction)[:cfg.block_size]])).to(device) ## There can be issues here if th text is shorter than any example in the dataset\n",
        "                                            ,torch.tensor(np.array([encode_state(resize_state(image))])).to(device) ## Not the correct goal image... Should mask this.\n",
        "                                            )\n",
        "                        # action = env.action_space.sample() # replace this with your policy inference\n",
        "                        if cfg.load_action_bounds:\n",
        "                            action = decode_action(action.cpu().detach().numpy()[0]) ## Add in the gripper close action\n",
        "                        else:\n",
        "                            action = np.concatenate((decode_action(action.cpu().detach().numpy()[0]), [0]), axis = -1) ## Add in the gripper close action\n",
        "                        obs, reward, done, truncated, info = env.step(action)\n",
        "                        reward = -np.linalg.norm(info[\"eof_to_obj1_diff\"])\n",
        "                        frames.append(image)\n",
        "                        rewards.append(reward)\n",
        "                        t=t+1\n",
        "\n",
        "                episode_stats = info.get('episode_stats', {})\n",
        "                print(\"Episode stats\", episode_stats)\n",
        "                print(f\"avg reward {np.mean(rewards):.8f}\")\n",
        "                if not cfg.testing:\n",
        "                    wandb.log({\"avg reward\": np.mean(rewards)})\n",
        "                import moviepy.editor as mpy\n",
        "                clip = mpy.ImageSequenceClip(list(frames), fps=20)\n",
        "                clip.write_videofile(log_dir+\"/sim-env-\"+str(iter)+\".mp4\", fps=20)\n",
        "                if not cfg.testing:\n",
        "                    wandb.log({\"example\": wandb.Video(log_dir+\"/sim-env-\"+str(iter)+\".mp4\")})\n",
        "\n",
        "        # sample a batch of data\n",
        "        xb, xg, xgi, yb = get_batch_grp('train', dataset_tmp, cfg.batch_size)\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, xg, xgi, yb)\n",
        "        loss.backward()\n",
        "\n",
        "        if (iter + 1) % cfg.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    if not cfg.testing:\n",
        "        wandb.finish()\n",
        "    return losses['val']\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = my_main()\n",
        "    print(\"results:\", results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHwNMLf0vL2M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mini-grp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}